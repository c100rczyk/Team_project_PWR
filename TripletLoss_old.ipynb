{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from pathlib import Path\n",
    "from keras import applications\n",
    "from keras import layers\n",
    "from keras import losses\n",
    "from keras import ops\n",
    "from keras import optimizers\n",
    "from keras import metrics\n",
    "from keras import Model\n",
    "from keras.applications import resnet\n",
    "from utilities import paths\n",
    "from utilities import preprocessing\n",
    "from utilities import visualization\n",
    "from main import target_shape\n",
    "from distance.DistanceLayer import  DistanceLayer\n",
    "from model.SiameseModel import SiameseModel"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T22:25:59.267839Z",
     "start_time": "2024-03-16T22:25:59.261065Z"
    }
   },
   "id": "7fcc6ea457891215",
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "anchor_images = sorted([paths.anchor_images_path + \"\\\\\" + f for f in os.listdir(paths.anchor_images_path)])\n",
    "positive_images = sorted([paths.positive_images_path + \"\\\\\" + f for f in os.listdir(paths.positive_images_path)])\n",
    "image_count = len(anchor_images)\n",
    "if image_count != len(positive_images):\n",
    "    raise Exception(\"Number of images in the datasets don't match\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T22:25:59.306657Z",
     "start_time": "2024-03-16T22:25:59.280631Z"
    }
   },
   "id": "2d69143c5a4b74a9",
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "anchor_dataset = tf.data.Dataset.from_tensor_slices(anchor_images)\n",
    "positive_dataset = tf.data.Dataset.from_tensor_slices(positive_images)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T22:25:59.461371Z",
     "start_time": "2024-03-16T22:25:59.361423Z"
    }
   },
   "id": "c5361d057d833e46",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(seed=42)\n",
    "rng.shuffle(anchor_images)\n",
    "rng.shuffle(positive_images)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T22:25:59.477026Z",
     "start_time": "2024-03-16T22:25:59.465881Z"
    }
   },
   "id": "343dc81ae70f7383",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "negative_images = anchor_images + positive_images\n",
    "np.random.RandomState(seed=32).shuffle(negative_images)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T22:25:59.491064Z",
     "start_time": "2024-03-16T22:25:59.480333Z"
    }
   },
   "id": "b7c7b3fd43ab6619",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "negative_dataset = tf.data.Dataset.from_tensor_slices(negative_images)\n",
    "negative_dataset = negative_dataset.shuffle(buffer_size=4096)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T22:25:59.568502Z",
     "start_time": "2024-03-16T22:25:59.494366Z"
    }
   },
   "id": "42cc514be2e85d0c",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.zip((anchor_dataset, positive_dataset, negative_dataset))\n",
    "dataset = dataset.shuffle(buffer_size=1024)\n",
    "dataset = dataset.map(preprocessing.preprocess_triplets)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T22:25:59.644682Z",
     "start_time": "2024-03-16T22:25:59.573918Z"
    }
   },
   "id": "4cd827be0cb94172",
   "execution_count": 40
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_dataset = dataset.take(round(image_count * 0.8)) # images for training\n",
    "val_dataset = dataset.skip(round(image_count * 0.8)) # images for validation"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T22:25:59.657176Z",
     "start_time": "2024-03-16T22:25:59.646691Z"
    }
   },
   "id": "13b37369573d7722",
   "execution_count": 41
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_dataset = train_dataset.batch(32, drop_remainder=False)\n",
    "train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "val_dataset = val_dataset.batch(32, drop_remainder=False)\n",
    "val_dataset = val_dataset.prefetch(tf.data.AUTOTUNE)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T22:25:59.676107Z",
     "start_time": "2024-03-16T22:25:59.659313Z"
    }
   },
   "id": "176833db1c6c81d9",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# visualization.visualize(*list(train_dataset.take(1).as_numpy_iterator())[0]) #https://www.geeksforgeeks.org/python-star-or-asterisk-operator/ "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T22:25:59.683960Z",
     "start_time": "2024-03-16T22:25:59.678234Z"
    }
   },
   "id": "e1caa0caae68a637",
   "execution_count": 43
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "base_cnn = resnet.ResNet50(\n",
    "    weights=\"imagenet\", input_shape=target_shape + (3,), include_top=False\n",
    ")\n",
    "\n",
    "flatten = layers.Flatten()(base_cnn.output)\n",
    "dense1 = layers.Dense(512, activation=\"relu\")(flatten)\n",
    "dense1 = layers.BatchNormalization()(dense1)\n",
    "dense2 = layers.Dense(256, activation=\"relu\")(dense1)\n",
    "dense2 = layers.BatchNormalization()(dense2)\n",
    "output = layers.Dense(256)(dense2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T22:26:01.469171Z",
     "start_time": "2024-03-16T22:25:59.687292Z"
    }
   },
   "id": "9970296f374f02da",
   "execution_count": 44
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "embedding = Model(base_cnn.input, output, name=\"Embedding\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T22:26:01.500505Z",
     "start_time": "2024-03-16T22:26:01.471306Z"
    }
   },
   "id": "fd8d7d369c71db2",
   "execution_count": 45
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "trainable = False\n",
    "for layer in base_cnn.layers:\n",
    "    if layer.name == \"conv5_block1_out\":\n",
    "        trainable = True\n",
    "    layer.trainable = trainable"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T22:26:01.512591Z",
     "start_time": "2024-03-16T22:26:01.503665Z"
    }
   },
   "id": "d621f2dd51e6b504",
   "execution_count": 46
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "anchor_input = layers.Input(name=\"anchor\", shape=target_shape + (3,))\n",
    "positive_input = layers.Input(name=\"positive\", shape=target_shape + (3,))\n",
    "negative_input = layers.Input(name=\"negative\", shape=target_shape + (3,))\n",
    "\n",
    "distances = DistanceLayer()(\n",
    "    embedding(resnet.preprocess_input(anchor_input)),\n",
    "    embedding(resnet.preprocess_input(positive_input)),\n",
    "    embedding(resnet.preprocess_input(negative_input)),\n",
    ")\n",
    "\n",
    "siamese_network = Model(\n",
    "    inputs=[anchor_input, positive_input, negative_input], outputs=distances\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T22:26:01.554747Z",
     "start_time": "2024-03-16T22:26:01.515916Z"
    }
   },
   "id": "e56b35842c209d2c",
   "execution_count": 47
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# siamese_model = SiameseModel(siamese_network)\n",
    "# siamese_model.compile(optimizer=optimizers.Adam(0.0001))\n",
    "# siamese_model.fit(train_dataset, epochs=10, validation_data=val_dataset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T22:26:01.562730Z",
     "start_time": "2024-03-16T22:26:01.556921Z"
    }
   },
   "id": "9651b61738d44c7c",
   "execution_count": 48
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-16T22:26:01.573891Z",
     "start_time": "2024-03-16T22:26:01.570322Z"
    }
   },
   "id": "c4cee0af777a4291",
   "execution_count": 48
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "ml",
   "language": "python",
   "display_name": "Python (ml)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
