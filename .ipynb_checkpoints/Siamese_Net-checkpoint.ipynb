{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f09aa91a-09e9-4c41-9b94-fe91a1f60da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9543 files belonging to 17 classes.\n",
      "Using 7635 files for training.\n",
      "Found 9543 files belonging to 17 classes.\n",
      "Using 1908 files for validation.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "If `subset` is set, `validation_split` must be set, and inversely.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 26\u001b[0m\n\u001b[1;32m     16\u001b[0m products_train \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mimage_dataset_from_directory(path, \n\u001b[1;32m     17\u001b[0m                                                           batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minferred\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     18\u001b[0m                                                           color_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrgb\u001b[39m\u001b[38;5;124m'\u001b[39m, image_size\u001b[38;5;241m=\u001b[39m(width_img,height_img), shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     19\u001b[0m                                                           validation_split \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m, subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m187\u001b[39m\n\u001b[1;32m     20\u001b[0m                                                           )\n\u001b[1;32m     21\u001b[0m products_val \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mimage_dataset_from_directory(path,\n\u001b[1;32m     22\u001b[0m                                                         batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minferred\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     23\u001b[0m                                                         color_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrgb\u001b[39m\u001b[38;5;124m'\u001b[39m, image_size\u001b[38;5;241m=\u001b[39m(width_img,height_img), shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     24\u001b[0m                                                         validation_split\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m187\u001b[39m\n\u001b[1;32m     25\u001b[0m                                                         )\n\u001b[0;32m---> 26\u001b[0m products_test \u001b[38;5;241m=\u001b[39m keras\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39mimage_dataset_from_directory(path_test,\n\u001b[1;32m     27\u001b[0m                                                          batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, labels\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minferred\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     28\u001b[0m                                                          color_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrgb\u001b[39m\u001b[38;5;124m'\u001b[39m, image_size\u001b[38;5;241m=\u001b[39m(width_img,height_img), shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m     29\u001b[0m                                                           subset\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboth\u001b[39m\u001b[38;5;124m\"\u001b[39m, seed\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m187\u001b[39m\n\u001b[1;32m     30\u001b[0m                                                         )\n\u001b[1;32m     33\u001b[0m class_names \u001b[38;5;241m=\u001b[39m products_train\u001b[38;5;241m.\u001b[39mclass_names\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(class_names)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/image_dataset_utils.py:206\u001b[0m, in \u001b[0;36mimage_dataset_from_directory\u001b[0;34m(directory, labels, label_mode, class_names, color_mode, batch_size, image_size, shuffle, seed, validation_split, subset, interpolation, follow_links, crop_to_aspect_ratio, data_format)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m interpolation \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m supported_interpolations:\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mArgument `interpolation` should be one of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    202\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msupported_interpolations\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    203\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: interpolation=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minterpolation\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    204\u001b[0m     )\n\u001b[0;32m--> 206\u001b[0m dataset_utils\u001b[38;5;241m.\u001b[39mcheck_validation_split_arg(\n\u001b[1;32m    207\u001b[0m     validation_split, subset, shuffle, seed\n\u001b[1;32m    208\u001b[0m )\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m seed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     seed \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandint(\u001b[38;5;241m1e6\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/keras/src/utils/dataset_utils.py:762\u001b[0m, in \u001b[0;36mcheck_validation_split_arg\u001b[0;34m(validation_split, subset, shuffle, seed)\u001b[0m\n\u001b[1;32m    757\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    758\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`validation_split` must be between 0 and 1, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    759\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreceived: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalidation_split\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    760\u001b[0m     )\n\u001b[1;32m    761\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (validation_split \u001b[38;5;129;01mor\u001b[39;00m subset) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (validation_split \u001b[38;5;129;01mand\u001b[39;00m subset):\n\u001b[0;32m--> 762\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    763\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf `subset` is set, `validation_split` must be set, and inversely.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    764\u001b[0m     )\n\u001b[1;32m    765\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m subset \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboth\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    766\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    767\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m`subset` must be either \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    768\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m or \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboth\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, received: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msubset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    769\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: If `subset` is set, `validation_split` must be set, and inversely."
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "#tf.data.Dataset\n",
    "path = \"/home/c100rczyk/VSCode/DataSets/Fruits_mini/Training\"\n",
    "path_test = \"/home/c100rczyk/VSCode/DataSets/Fruits_mini/Test\"\n",
    "width_img = 100\n",
    "height_img = 100\n",
    "\n",
    "# generating dataset tf.data.Dataset from file in directory\n",
    "# for training and validation data\n",
    "# processing data on an ongoing basis during training network. Data are loading from memory RAM in batches\n",
    "products_train = keras.utils.image_dataset_from_directory(path, \n",
    "                                                          batch_size=128, labels='inferred',\n",
    "                                                          color_mode='rgb', image_size=(width_img,height_img), shuffle=True,\n",
    "                                                          validation_split = 0.2, subset=\"training\", seed=187\n",
    "                                                          )\n",
    "products_val = keras.utils.image_dataset_from_directory(path,\n",
    "                                                        batch_size=128, labels='inferred',\n",
    "                                                        color_mode='rgb', image_size=(width_img,height_img), shuffle=True,\n",
    "                                                        validation_split=0.2, subset=\"validation\", seed=187\n",
    "                                                        )\n",
    "products_test = keras.utils.image_dataset_from_directory(path_test,\n",
    "                                                         batch_size=64, labels='inferred',\n",
    "                                                         color_mode='rgb', image_size=(width_img,height_img), shuffle=True,\n",
    "                                                         validation_split = 0.2, subset=\"both\", seed=187\n",
    "                                                        )\n",
    "\n",
    "\n",
    "class_names = products_train.class_names\n",
    "print(class_names)\n",
    "\n",
    "# get one batch\n",
    "for image, labels in products_train.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3,3,i+1)\n",
    "        plt.imshow(image[i].numpy().astype(\"uint8\"))\n",
    "        plt.title(class_names[labels[i]])\n",
    "        plt.axis('off')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15fc0d12-87e5-4f2b-9665-6908c22b8736",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17,)\n"
     ]
    }
   ],
   "source": [
    "# how many classes \n",
    "print(np.shape(products_train.class_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5fe2755-84a4-4d40-964e-1dcbae2fd9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 100, 100, 3)\n",
      "(256, 2, 100, 100, 3)\n"
     ]
    }
   ],
   "source": [
    "# Create pairs of images. Matching pairs with label 0  and  mismatched pairs as labels 1\n",
    "\n",
    "\n",
    "def make_pairs(x,y):\n",
    "    \"\"\"\n",
    "    Creating pairs. label 0 - matching pairs  , label 1 - mismatched pairs\n",
    "\n",
    "    Arguments: \n",
    "        x - images\n",
    "        y - labels \n",
    "\n",
    "    Returns:\n",
    "        list of pairs\n",
    "    \"\"\"\n",
    "    num_classes = np.shape(products_train.class_names)[0] \n",
    "    digit_indices = [np.where(y == i)[0] for i in range(num_classes)]\n",
    "    #print(digit_indices)\n",
    "    pairs = []\n",
    "    labels = []\n",
    "\n",
    "    #work on 128 data batch only every time\n",
    "    for i in range(len(x)):\n",
    "        # add matching example\n",
    "        x1 = x[i]\n",
    "        label1 = y[i]\n",
    "        idx2 = random.choice(digit_indices[label1])\n",
    "        x2 = x[idx2]\n",
    "\n",
    "        pairs += [[x1,x2]]\n",
    "        labels += [0]\n",
    "\n",
    "        # add a non-matching example\n",
    "        label2 = random.randint(0 , num_classes-1)\n",
    "        while label2 == label1:\n",
    "            label2 = random.randint(0, num_classes-1) \n",
    "        idx2 = random.choice(digit_indices[label2])\n",
    "        x2 = x[idx2]\n",
    "\n",
    "        pairs += [[x1,x2]]\n",
    "        labels += [1]\n",
    "\n",
    "    return np.array(pairs), np.array(labels).astype(\"float32\")\n",
    "\n",
    "    \n",
    "# get images and his labels apart\n",
    "(train_images, train_labels) = next(iter(products_train.take(1)))\n",
    "(val_images, val_labels) = next(iter(products_val.take(1)))\n",
    "\n",
    "print(train_images.shape)\n",
    "#print(train_labels.shape)\n",
    "#print(len(train_images))\n",
    "\n",
    "#train_images = train_images.numpy()   # it's not necesary   tensor format is ok\n",
    "#train_labels = train_labels.numpy()\n",
    "\n",
    "pairs_train, labels_train = make_pairs(train_images, train_labels)\n",
    "pairs_val, labels_val = make_pairs(val_images, val_labels)\n",
    "                                \n",
    "\n",
    "print(pairs_train.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "c413223f-fbd2-49a2-9149-cd6bede4491c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 100, 100, 3)\n",
      "(128,)\n"
     ]
    }
   ],
   "source": [
    "# how many data has each batch:   (sÄ… to tensory)\n",
    "for img_batch, label_batch in products_train:\n",
    "    print(img_batch.shape)\n",
    "    print(label_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da14a19b-e769-4eec-9673-2db21974aaed",
   "metadata": {},
   "source": [
    "### What we have:\n",
    "Now we have first batch 128 images. And produced 256 pairs of images : 128 matched and 128 non-matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b33ca71-ad40-4989-b7ae-192fc16f4eda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
